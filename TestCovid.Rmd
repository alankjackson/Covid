---
title: "Test Covid stuff"
author: "Alan Jackson"
date: "3/11/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(rvest)
library(ggplot2)
library(httr)
library(xml2)
library(broom)
library(stringr)
library(leaflet)
library(leafpop)

options(stringsAsFactors = FALSE)

knitr::opts_chunk$set(echo = TRUE)
```

## retrieve data

Painfully retrieved. There is a bad certificate for the website, I guess,
and it took quite a bit of futzing to find a way around that problem.

Then the output of RCurl needs to be passed through read_html to be acceptable
to html_nodes. Sigh.

DSHS will update the state case count each day by 10 a.m. Central Time.
//*[@id="ctl00_ContentPlaceHolder1_uxContent"]/div[2]/div/table

/html/body/form/div[4]/div/div[3]/div[2]/div/div/div[2]/div/table

```{r scrape}
url <- "https://www.dshs.state.tx.us/news/updates.shtm#coronavirus"
#   Bad idea, disabling certificate check
page <- RCurl::getURL("https://www.dshs.state.tx.us/news/updates.shtm#coronavirus", ssl.verifyhost = 0L, ssl.verifypeer = 0L)

mytable <- read_html(page) %>% 
  #html_nodes(xpath='//*[@id="ctl00_ContentPlaceHolder1_uxContent"]/div[2]/table') %>% 
  html_nodes(xpath='/html/body/form/div[4]/div/div[3]/div[2]/div/div/div[2]/div/table') %>% 
  html_table()

mytable <- mytable[[1]]
names(mytable) <- c("County", "Cases")
mytable <- mytable %>% mutate(Date=lubridate::today())

testing_status <- read_html(page) %>% 
  html_nodes(xpath='/html/body/form/div[4]/div/div[3]/div[2]/div/div/div[2]/table[1]') %>% 
  html_table()

testing_status <-   testing_status[[1]][["X2"]] %>% 
  str_remove_all("\\D") %>% 
  tibble(x=.) %>% 
  mutate(y=c("Total", "Public", "Private")) %>% 
  spread(key=y, value=x)

testing_status <- testing_status %>% mutate(Date=lubridate::today())

```

## Append new data to old data and save

```{r append}
# Read in the old data
CovidData <- readRDS("/home/ajackson/Dropbox/Rprojects/Covid/Covid.rds")
# append the new data
CovidData <- bind_rows(CovidData, mytable)
# Save an accumulated file in case of a failure
saveRDS(CovidData,paste0("/home/ajackson/Dropbox/Rprojects/Covid/",lubridate::today(),"_Covid.rds"))
# Save the real file for later use
saveRDS(CovidData,"/home/ajackson/Dropbox/Rprojects/Covid/Covid.rds")

# Read in the old data
TestingData <- readRDS("/home/ajackson/Dropbox/Rprojects/Covid/Testing.rds")
# append the new data
TestingData <- bind_rows(TestingData, testing_status)
# Save an accumulated file in case of a failure
saveRDS(TestingData,paste0("/home/ajackson/Dropbox/Rprojects/Covid/",lubridate::today(),"_Testing.rds"))
# Save the real file for later use
saveRDS(TestingData,"/home/ajackson/Dropbox/Rprojects/Covid/Testing.rds")
```

## Test some plotting code to get that right

```{r plotting}
CovidData <- readRDS("/home/ajackson/Dropbox/Rprojects/Covid/Covid.rds")

foobar <- CovidData %>% filter(County=="Harris"|County=="Fort Bend"|County=="Galveston"|County=="Waller"|County=="Montgomery"|County=="Liberty"|County=="Brazoria"|County=="Chambers"|County=="Austin") %>% group_by(Date) %>% summarize_at("Cases", sum)
foobar <- Counties %>% filter(County=="Collin"|County=="Dallas"|County=="Denton"|County=="Ellis"|County=="Hood"|County=="Hunt"|County=="Johnson"|County=="Kaufman"|County=="Parker"|County=="Rockwall"|County=="Somervell"|County=="Tarrant"|County=="Wise")
foobar <- Counties %>% filter(County=="Atascosa" |County=="Bandera" |County=="Bexar" |County=="Comal" |County=="Guadalupe" |County=="Kendall" |County=="Medina" |County=="Wilson") %>% summarise_at("Population",sum)
foobar <- Counties %>% filter(County=="Bastrop" |County=="Caldwell" |County=="Hays" |County=="Travis" |County=="Williamson") %>% summarise_at("Population",sum)
     

target <- c("Harris", "Fort Bend", "Galveston", "Waller", "Montgomery", "Liberty", "Brazoria", "Chambers", "Austin") 
foobar <- CovidData %>% filter(County %in% target) %>% group_by(Date) %>% summarize_at("Cases", sum)
# Clean up footnotes

CovidData$County <- str_replace(CovidData$County, "\\d", "")

# Load population of counties into tibble
Counties <- tribble(
  ~County, ~Population,
  "Total", 28700000, "Harris", 4602523, "Dallas", 2586552, "Tarrant", 2019977,
  "Bexar", 1925865, "Travis", 1203166, "Collin", 944350, "Hidalgo", 849389,
  "El Paso", 837654, "Denton", 807047, "Fort Bend", 739342,
  "Montgomery", 554445, "Williamson", 527057, "Cameron", 421750,
  "Nueces", 360486, "Brazoria", 353999, "Bell", 342236,
  "Galveston", 327089, "Lubbock", 301454, "Webb", 272053,
  "Jefferson", 255210, "McLennan", 248429, "Smith", 225015,
  "Brazos", 219193, "Hays", 204150, "Ellis", 168838,
  "Midland", 164194, "Johnson", 163475, "Ector", 158342,
  "Guadalupe", 155137, "Taylor", 136348, "Comal", 135097,
  "Randall", 132475, "Wichita", 131818, "Parker", 129802,
  "Grayson", 128560, "Gregg", 123494, "Potter", 120899,
  "Kaufman", 118910, "Tom Green", 117466, "Bowie", 93858,
  "Rockwall", 93642, "Hunt", 92152, "Victoria", 91970,
  "Angelina", 87607, "Orange", 84047, "Bastrop", 82577,
  "Liberty", 81862, "Henderson", 80460, "Coryell", 75389,
  "Walker", 71539, "San Patricio", 67046, "Harrison", 66645,
  "Nacogdoches", 65558, "Wise", 64639, "Starr", 63894,
  "Maverick", 57970, "Anderson", 57863, "Hood", 56901,
  "Hardin", 56379, "Van Zandt", 54368, "Rusk", 53595,
  "Cherokee", 51903, "Kerr", 51365, "Waller", 49987,
  "Lamar", 49532, "Medina", 49334, "Val Verde", 49027,
  "Atascosa", 48828, "Navarro", 48583, "Wilson", 48198,
  "Polk", 47837, "Burnet", 45750, "Wood", 43815,
  "Kendall", 41982, "Wharton", 41551, "Erath", 41482,
  "Caldwell", 41401, "Jim Wells", 41192, "Upshur", 40769,
  "Chambers", 40292, "Cooke", 39571, "Brown", 37834,
  "Matagorda", 36743, "Howard", 36667, "Hopkins", 36240,
  "Jasper", 35504, "Hill", 35399, "Washington", 34796,
  "Fannin", 34175, "Hale", 34113, "Titus", 32730,
  "Bee", 32691, "Kleberg", 31425, "Cass", 30087,
  "Austin", 29565, "Palo Pinto", 28317, "San Jacinto", 27819,
  "Grimes", 27630, "Uvalde", 27009, "Gillespie", 26208,
  "Shelby", 25478, "Fayette", 25066, "Aransas", 24763,
  "Milam", 24664, "Limestone", 23515, "Panola", 23440,
  "Hockley", 23162, "Houston", 22955, "Gray", 22685,
  "Calhoun", 21807, "Moore", 21801, "Bandera", 21763,
  "Willacy", 21754, "Hutchinson", 21571, "Tyler", 21496,
  "Colorado", 21022, "Gonzales", 20667, "Lampasas and Llano", 20640,
  "DeWitt", 20435, "Gaines", 20321, "Lavaca", 19941,
  "Jones", 19891, "Freestone", 19709, "Montague", 19409,
  "Frio", 19394, "Deaf Smith", 18899, "Eastland", 18270,
  "Bosque", 18122, "Young", 18114, "Burleson", 17863,
  "Andrews", 17818, "Falls", 17299, "Scurry", 17239,
  "Leon", 17098, "Lee", 16952, "Robertson", 16890,
  "Pecos", 15797, "Karnes", 15387, "Reeves", 15125,
  "Nolan", 14966, "Jackson", 14820, "Trinity", 14569,
  "Zapata", 14369, "Madison", 14128, "Newton", 14057,
  "Callahan", 13770, "Comanche", 13495, "Lamb", 13262,
  "Dawson", 12964, "Wilbarger", 12906, "Camp", 12813,
  "Terry", 12615, "Morris", 12424, "Red River", 12275,
  "Zavala", 12131, "Live Oak", 12123, "Ward", 11586,
  "Rains", 11473, "Duval", 11355, "Blanco", 11279,
  "Franklin", 10679, "Dimmit", 10663, "Sabine", 10458,
  "Clay", 10387, "Ochiltree", 10348, "Runnels", 10310,
  "Marion", 10083, "Parmer", 9852, "Stephens", 9372,
  "Brewster", 9216, "Jack", 8842, "Archer", 8789,
  "Somervell", 8743, "Yoakum", 8571, "Mitchell", 8558,
  "Coleman", 8391, "San Augustine", 8327, "Hamilton", 8269,
  "McCulloch", 8098, "Winkler", 7802, "Castro", 7787,
  "Goliad", 7531, "Swisher", 7484, "La Salle", 7409,
  "Dallam", 7243, "Refugio", 7236, "Childress", 7226,
  "Brooks", 7180, "Presidio", 7123, "Bailey", 7092,
  "Garza", 6288, "Carson", 6032, "San Saba", 5962,
  "Floyd", 5872, "Crosby", 5861, "Haskell", 5809,
  "Lynn", 5808, "Hartley", 5767, "Martin", 5614,
  "Hansford", 5547, "Wheeler", 5482, "Jim Hogg", 5282,
  "Delta", 5215, "Mills", 4902, "Crane", 4839,
  "Kimble", 4408, "Concho", 4233, "Mason", 4161,
  "Hudspeth", 4098, "Hemphill", 4061, "Hardeman", 3952,
  "Fisher", 3883, "Sutton", 3865, "Reagan", 3752,
  "Knox", 3733, "Kinney", 3675, "Upton", 3634,
  "Crockett", 3633, "Baylor", 3591, "Lipscomb", 3469,
  "Real", 3389, "Donley", 3387, "Shackelford", 3311,
  "Coke", 3275, "Hall", 3074, "Schleicher", 3061,
  "Sherman", 3058, "Collingsworth", 2996, "Cochran", 2904,
  "Culberson", 2241, "Jeff Davis", 2234, "Dickens", 2216,
  "Menard", 2123, "Oldham", 2090, "Edwards", 2055,
  "Armstrong", 1916, "Cottle", 1623, "Throckmorton", 1567,
  "Briscoe", 1546, "Irion", 1524, "Glasscock", 1430,
  "Foard", 1408, "Stonewall", 1385, "Motley", 1156,
  "Sterling", 1141, "Roberts", 885, "Terrell", 862,
  "Kent", 749, "Borden", 665, "McMullen", 662,
  "Kenedy", 595, "King", 228, "Loving", 102
)

# Estimated percent undercount

undercount <- 0.5
CovidData <- CovidData %>% 
  mutate(Estimate=Cases/undercount)

# First calculate some useful stuff

County <- "Total"
CountyLabel <- "Texas"
County <- "Harris"
CountyLabel <- "Harris County"
# Calc days since March 11

CovidData <- CovidData %>% 
  mutate(Days=as.integer(Date-ymd("2020-03-11")))

# Linear fits to log(cases)

LogFits <- CovidData %>% 
  split(.$County) %>% 
  map(~lm(log10(Cases)~Days, data=.x)) %>% 
  map_df(tidy, .id="County" ) %>% 
  filter(County==!!County)

LogFits_est <- CovidData %>% 
  split(.$County) %>% 
  map(~lm(log10(Estimate)~Days, data=.x)) %>% 
  map_df(tidy, .id="County" ) %>% 
  filter(County==!!County)


# When is probability of 1% contact reached?

Population <- Counties$Population[Counties$County==County]
b <- LogFits[1,3][[1]]
b_est <- LogFits_est[1,3][[1]]
m <- LogFits[2,3][[1]]
m_est <- LogFits_est[2,3][[1]]
TestDays <- as.integer(today() - ymd("2020-03-11")) + c(0,5,10) + 1
TestDates <- today() + c(0,5,10)
Crowdsize <- signif((0.01*Population)/(10**(TestDays*m+b)), 2)
Crowdsize_est <- signif((0.01*Population)/(10**(TestDays*m_est+b_est)), 2)
EqText <- paste0("Fit is log(Cases) = ",signif(m,3),"*Days + ",signif(b,3))
grob <- grid::grid.text(EqText, x=0.7,  y=0.1, gp=grid::gpar(col="black", fontsize=10))

CrowdText <- "Sizes of groups to avoid to keep\nchance of meeting a contagious\nperson below 1%"
grob2 <- grid::grid.text(CrowdText, x=0.3,  y=0.8, gp=grid::gpar(col="black", fontsize=10))

# Build exponential line for plot
dayseq <- 0:(as.integer(today() - ymd("2020-03-11")) + 10)
dateseq <- as_date(ymd("2020-03-11"):(today()+10))
Cases <- 10**(m*dayseq+b)
Cases_est <- 10**(m_est*dayseq+b_est)
ExpLine <- tibble( Days=dayseq, Date=dateseq, Cases=Cases )
ExpLine_est <- tibble( Days=dayseq, Date=dateseq, Estimate=Cases_est )
#  Scale cases so similar scaling to days
CaseScale <- length(dateseq)/max(Cases)
Delta <- (Cases[TestDays] - Cases[TestDays-1])*CaseScale
#Delta <- max(Delta)/Delta
r <-  2 # radius distance
x_nudge <- -r*cos((pi/2 -atan(Delta)))- 0.5
y_nudge <- r*sin((pi/2 -atan(Delta)))/CaseScale
y_extra <- max(ExpLine$Cases)/30
#y_nudge <- ((sin(atan(Delta))*Delta/2)*cos(pi/2-atan(Delta))/CaseScale)

# Build label tibble
CrowdLabels <- tibble(Date=TestDates,
                        Crowd=Crowdsize,
                        Cases=Cases[TestDays],
                        Delta=Delta,
                        x_nudge=x_nudge,
                        y_nudge=y_nudge)

CrowdLabels_est <- tibble(Date=TestDates,
                        Crowd=Crowdsize_est,
                        Cases=Cases_est[TestDays],
                        Delta=Delta,
                        x_nudge=x_nudge,
                        y_nudge=y_nudge)

# Linear scale 
p <- CovidData %>% filter(County==!!County) %>% 
  ggplot(aes(x=Date, y=Cases)) +
  geom_col(alpha = 2/3)+
  expand_limits(x = today()+10) +
  geom_line(data=ExpLine,
              aes(x=Date, y=Cases,
              color="blue"),
              size=1,
              linetype="dashed") +
  geom_line(data=ExpLine[1:(nrow(ExpLine)-10),],
              aes(x=Date, y=Cases,
              color="blue"),
              size=1,
              linetype="solid") +
  annotation_custom(grob) +
  annotation_custom(grob2) +
  labs(title=paste0("CORVID-19 Cases in ",CountyLabel))

Est_layer <-   geom_line(data=ExpLine_est,
                          aes(x=Date, y=Estimate,
                          color="purple"),
                          size=1,
                          linetype="dotted")
Est_legend <- theme(legend.position="right")

CrowdLayer1 <-  geom_point(data=CrowdLabels,
                     aes(x=Date, y=Cases)) 
CrowdLayer2 <- geom_label(data=CrowdLabels,
                    aes(x=Date, y=Cases, label=Crowd),
                    nudge_x=x_nudge,
                    nudge_y=y_nudge) 
CrowdLayer3 <- geom_segment(data=CrowdLabels, 
                    aes(x = Date+x_nudge+.5, 
                       xend = Date,
                       y = Cases + y_nudge - y_extra,
                       yend = Cases), 
                    colour = "black", 
                    size=0.5) 

CrowdLayerest1 <-  geom_point(data=CrowdLabels_est,
                     aes(x=Date, y=Cases)) 
CrowdLayerest2 <- geom_label(data=CrowdLabels_est,
                    aes(x=Date, y=Cases, label=Crowd),
                    nudge_x=x_nudge,
                    nudge_y=y_nudge) 
CrowdLayerest3 <- geom_segment(data=CrowdLabels_est, 
                    aes(x = Date+x_nudge+.5, 
                       xend = Date,
                       y = Cases + y_nudge - y_extra,
                       yend = Cases), 
                    colour = "black", 
                    size=0.5) 
Legend_layer <- scale_color_discrete(name = "Models", labels = c("Data", "Estimate"))


p + list(CrowdLayer1, CrowdLayer2, CrowdLayer3, Est_layer, 
         Legend_layer,
         CrowdLayerest1, CrowdLayerest2, CrowdLayerest3)

# Log scale

CovidData %>% filter(County==!!County) %>% 
  ggplot(aes(x=Date, y=Cases)) +
  geom_col(alpha = 2/3) +
  scale_y_log10() +
  expand_limits(x = today()+10) +
  geom_smooth(method=lm,   # Add linear regression lines
                se=FALSE,    # Don't add shaded confidence region
                fullrange=TRUE,
                linetype="dashed") +   # Extend regression lines
  geom_smooth(method=lm,   # Add linear regression lines
                se=FALSE,    # Don't add shaded confidence region
                fullrange=FALSE,
                linetype="solid") + # Don't Extend regression lines
  labs(title="CORVID-19 Cases in Texas", y="Cases on a Log Scale")

```



## mapping

```{r maps}
#DF <- readRDS(gzcon(url(paste0(DataLocation, "Covid.rds"))))

#   Get county outlines
#USA <- raster::getData("GADM", country = "usa", level = 2)
#Counties <- Counties %>% mutate(state="Texas")
#Texas <- USA[USA@data$NAME_1 == "Texas", ]

Texas <- readRDS("/home/ajackson/Dropbox/Rprojects/Datasets/Archive/Texas_County_Outlines.rds")
smallTexas <- rmapshaper::ms_simplify(Texas, keep=0.01)

saveRDS(smallTexas, "/home/ajackson/mirrors/ajackson/SharedData/Texas_County_Outlines_lowres.rds")

init_zoom <- 6
MapCenter <- c(-99.9018, 31.9686) # center of state
LastDate <- CovidData[nrow(CovidData),]$Date

TodayData <- CovidData %>% filter(Date==LastDate) %>% 
  filter(County!="Pending County Assignment") %>% 
  left_join(., Counties, by="County") %>% 
  mutate(percapita=Cases/Population*100000)

temp <-  merge(Texas, TodayData,
              by.x = c("County"), by.y = c("County"),
              all.x = TRUE) 

#   Reduce the resolution in favor of speed

temp <- rmapshaper::ms_simplify(temp)

#    Per Capita
# Create a continuous palette function
palcap <- colorNumeric(
  na.color = "transparent",
  palette = heat.colors(8),
  reverse=TRUE,
  domain = temp$percapita)

palcase <- colorNumeric(
  na.color = "transparent",
  palette = heat.colors(8),
  reverse=TRUE,
  domain = temp$Cases)

#mypal <- colorNumeric(palette = "viridis", domain = temp$percapita, na.color = "transparent")

temp <- temp %>%
  mutate(percapita=signif(percapita,3)) %>% 
  mutate(Label=paste0(County, " county<br>",
                              Cases, " total cases<br>",
                              percapita, " cases per 100,000"))       
  temp$Label=htmltools::HTML(temp$Label)

labs <- lapply(seq(nrow(temp)), function(i) {
  paste0( temp[i, "County"], '<br>', 
          temp[i, "Cases"],'<br>', 
          temp[i, "percapita"]) 
})
  
leaflet(TodayData) %>% 
  setView(lng = MapCenter[1] , lat = MapCenter[2], zoom = init_zoom ) %>%   
  addTiles() %>%
  addPolygons(data = temp, 
              group="cases",
              stroke = TRUE,
              weight = 1,
              smoothFactor = 0.2, 
              fillOpacity = 0.7,
              label = ~Label,
              fillColor = ~palcase(temp$Cases)) %>% 
  addLegend("bottomleft", pal = palcase, values = ~Cases, 
    title = "Total Cases",
    opacity = 1)

leaflet(TodayData) %>% 
  setView(lng = MapCenter[1] , lat = MapCenter[2], zoom = init_zoom ) %>%   
  addTiles() %>%
  addPolygons(data=temp,
              group="percapita",
              stroke = TRUE,
              weight=1,
              fillColor = ~palcap(percapita),
              fillOpacity = 0.7,
              label = ~County) %>% 
  addLegend("bottomleft", pal = palcap, values = ~percapita, 
    title = "Cases per</br>x100,000",
    opacity = 1
  )

 ggplot(data = temp) +
    geom_sf() +
    geom_sf(data = temp, aes(fill = Cases)) +
    scale_fill_viridis_c(trans = "sqrt", alpha = .4) 
  
  
```

## reprex

```{r reprex}
library(tidyverse)
library(leaflet)

#   Get county outlines
USA <- raster::getData("GADM", country = "usa", level = 2)

Texas <- USA[USA@data$NAME_1 == "Texas", ]

init_zoom <- 6
MapCenter <- c(-99.9018, 31.9686) # center of state

TodayData <- tribble(
    ~County,    ~Cases,       ~Population, ~percapita,
#  "Bell",         1,       342236,     0.292,
#  "Bexar",        4,      1925865,     0.208,
#  "Bowie",        1,        93858,     1.07,
#  "Brazoria",     2,       353999,     0.565,
#  "Brazos",       1,       219193,     0.456,
#  "Collin",       6,       944350,     0.635,
#  "Dallas",      15,      2586552,     0.580,
#  "Denton",       4,       807047,     0.496,
  "El Paso",      3,       837654,     0.358
#  "Fort Bend",    9,       739342,     1.22,
#  "Galveston",    2,       327089,     0.611,
#  "Gregg",        1,       123494,     0.810,
#  "Harris",      10,      4602523,     0.217,
#  "Hays",         1,       204150,     0.490,
#  "Lavaca",       1,        19941,     5.01,
#  "Matagorda",    1,        36743,     2.72,
#  "Medina",       1,        49334,     2.03,
#  "Montgomery",   3,       554445,     0.541,
#  "Rusk",         1,        53595,     1.87,
#  "Smith",        5,       225015,     2.22,
#  "Tarrant",      5,      2019977,     0.248,
#  "Travis",       4,      1203166,     0.332,
#  "Webb",         1,       272053,     0.368
)

temp <-  merge(Texas, TodayData,
              by.x = c("NAME_2"), by.y = c("County"),
              all.x = TRUE) 

palcase <- colorNumeric(
  na.color = "transparent",
  palette = rev(heat.colors(8)),
  domain = temp$Cases)

leaflet(TodayData) %>% 
  setView(lng = MapCenter[1] , lat = MapCenter[2], zoom = init_zoom ) %>%   
  addTiles() %>%
  addPolygons(data = Texas, 
              stroke = TRUE,
              weight = 1,
              smoothFactor = 0.2, 
              fillOpacity = 0.5,
              label = ~NAME_2,
              fillColor = ~palcase(temp$Cases))

```




